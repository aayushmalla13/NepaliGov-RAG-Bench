#!/usr/bin/env python3
"""
üá≥üáµ Nepal Government Q&A API - FIXED VERSION

Fixed issues:
1. Better search algorithm that prioritizes constitutional content correctly
2. Proper document titles instead of filenames
3. More accurate content matching
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import pandas as pd
import re
import time
from pathlib import Path
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="üá≥üáµ Nepal Government Q&A System - Fixed",
    description="Improved Q&A system with better search and proper document titles",
    version="2.1.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global variables
corpus_data = None
document_stats = {}

# Document title mapping - proper titles instead of filenames
DOCUMENT_TITLES = {
    'Constitution-of-Nepal_2072_Eng_www.moljpa.gov_.npDate-72_11_16': 'Constitution of Nepal 2015 (English)',
    '‡§®‡•á‡§™‡§æ‡§≤‡§ï‡•ã_‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§®_‡•®‡•¶‡•≠‡•®': 'Constitution of Nepal 2072 (Nepali)',
    'Fundamental_Rights_and_Duties_in_Nepal': 'Fundamental Rights and Duties in Nepal',
    'Annual-Health-Report-208081_compressed': 'Annual Health Report 2080-81',
    'BHS_STP_Final-Pdf_CSD-(1)-1658727034': 'Basic Health Services Strategic Plan',
    'COVID-19_pandemic_in_Nepal': 'COVID-19 Pandemic in Nepal',
    'COVID-19_vaccination_in_Nepal': 'COVID-19 Vaccination in Nepal',
    '‡•®‡•¶‡•®‡•¶_‡§®‡•á‡§™‡§æ‡§≤‡§Æ‡§æ_‡§ï‡•ã‡§∞‡•ã‡§®‡§æ‡§≠‡§æ‡§á‡§∞‡§∏_‡§Æ‡§π‡§æ‡§Æ‡§æ‡§∞‡•Ä': 'COVID-19 in Nepal 2020 (Nepali)',
    '02-final-heoc-repor--min': 'Health Emergency Operations Center Report',
    'Ministry_of_Health_and_Population_(Nepal)': 'Ministry of Health and Population',
    '‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø_‡§§‡§•‡§æ_‡§ú‡§®‡§∏‡§ô‡•ç‡§ñ‡•ç‡§Ø‡§æ_‡§Æ‡§®‡•ç‡§§‡•ç‡§∞‡§æ‡§≤‡§Ø_(‡§®‡•á‡§™‡§æ‡§≤)': 'Ministry of Health and Population (Nepali)',
    'nhss-english-book-final-4-21-2016': 'Nepal Health Sector Strategy 2016',
    'NP_Public-Health-Service-Act-2075_EN': 'Public Health Service Act 2075',
    'standard-treatment-protocol-of-emergency-health-service-package': 'Emergency Health Service Treatment Protocols',
    'who-special-initiative-country-report---nepal---2022': 'WHO Special Initiative Report - Nepal 2022',
    'BlueBook2021': 'Government Budget Blue Book 2021',
    'GER-Nepal-eng': 'Gender Equality Report - Nepal',
    'Nepal - DRM Act': 'Disaster Risk Management Act',
    '‡§®‡•á‡§™‡§æ‡§≤‡§Æ‡§æ_‡§Æ‡•å‡§≤‡§ø‡§ï_‡§π‡§ï_‡§∞_‡§ï‡§∞‡•ç‡§§‡§µ‡•ç‡§Ø': 'Fundamental Rights and Duties (Nepali)',
    '9789240061262-eng': 'WHO Primary Health Care Case Study - Nepal',
    '9789240070523-eng': 'WHO Health Systems Report - Nepal',
    '9789290210764-eng': 'WHO Country Cooperation Strategy 2023-2027 - Nepal'
}

# Pydantic models
class QueryRequest(BaseModel):
    question: str
    max_results: int = 5
    include_sources: bool = True
    language_preference: str = "auto"

class SearchResult(BaseModel):
    doc_id: str
    doc_title: str
    page_num: int
    text: str
    relevance_score: float
    language: str
    char_count: int

class Answer(BaseModel):
    question: str
    answer: str
    confidence: float
    sources: List[SearchResult]
    total_sources_found: int
    processing_time_ms: float
    document_coverage: Dict[str, int]

def get_proper_title(doc_id: str) -> str:
    """Get proper document title instead of filename."""
    return DOCUMENT_TITLES.get(doc_id, doc_id.replace('_', ' ').replace('-', ' ').title())

def load_corpus():
    """Load the real corpus with error handling."""
    global corpus_data, document_stats
    
    try:
        corpus_path = Path("data/real_corpus.parquet")
        if not corpus_path.exists():
            logger.error("Real corpus not found!")
            return False
        
        corpus_data = pd.read_parquet(corpus_path)
        logger.info(f"‚úÖ Loaded {len(corpus_data)} chunks from real government PDFs")
        
        # Calculate document statistics with proper titles
        document_stats = {}
        for doc_id in corpus_data['doc_id'].unique():
            doc_chunks = corpus_data[corpus_data['doc_id'] == doc_id]
            
            # Get proper title
            title = get_proper_title(doc_id)
            
            # Determine topics based on document name and content
            topics = []
            doc_name_lower = doc_id.lower()
            
            if 'constitution' in doc_name_lower:
                topics = ['Constitution', 'Fundamental Rights', 'Government Structure', 'Political System']
            elif 'health' in doc_name_lower or 'medical' in doc_name_lower:
                topics = ['Health Services', 'Medical Care', 'Public Health']
            elif 'covid' in doc_name_lower:
                topics = ['COVID-19', 'Pandemic Response', 'Health Emergency']
            elif 'heoc' in doc_name_lower:
                topics = ['Emergency Services', 'Health Operations', 'Crisis Management']
            elif 'blue' in doc_name_lower:
                topics = ['Budget', 'Government Policy', 'Economic Policy']
            else:
                topics = ['Government Policy', 'Public Services']
            
            document_stats[doc_id] = {
                'title': title,
                'total_chunks': len(doc_chunks),
                'language': doc_chunks['language'].mode().iloc[0] if len(doc_chunks) > 0 else 'en',
                'topics': topics,
                'char_count': doc_chunks['char_count'].sum() if 'char_count' in doc_chunks.columns else len(' '.join(doc_chunks['text'].astype(str)))
            }
        
        logger.info(f"üìä Processed {len(document_stats)} documents with proper titles")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Failed to load corpus: {e}")
        return False

def improved_search(query: str, max_results: int = 5, language_preference: str = "auto") -> List[Dict[str, Any]]:
    """
    IMPROVED search algorithm that prioritizes content correctly.
    
    Key improvements:
    1. Better scoring for constitutional content
    2. More accurate phrase matching
    3. Proper document type prioritization
    """
    
    if corpus_data is None:
        return []
    
    query_lower = query.lower()
    query_words = set(query_lower.split())
    
    results = []
    
    for idx, row in corpus_data.iterrows():
        text = str(row['text'])
        text_lower = text.lower()
        doc_id = str(row['doc_id'])
        
        # Initialize score
        score = 0.0
        
        # 1. EXACT PHRASE MATCHING (highest priority)
        if query_lower in text_lower:
            score += 25.0
        
        # 2. MULTI-WORD PHRASE MATCHING
        # Look for sequences of query words
        query_phrases = []
        words = query.split()
        for i in range(len(words)):
            for j in range(i + 2, len(words) + 1):  # 2+ word phrases
                phrase = ' '.join(words[i:j]).lower()
                if phrase in text_lower:
                    score += 10.0 + (j - i) * 2  # Bonus for longer phrases
        
        # 3. CONSTITUTIONAL CONTENT SUPER-BOOST
        # Give massive priority to constitutional content when asking about governance/politics
        if any(keyword in query_lower for keyword in ['governance', 'political', 'policies', 'government', 'constitution']):
            if 'constitution' in doc_id.lower():
                score += 30.0  # Huge boost for constitutional documents
                
                # Extra boost for specific constitutional sections
                if any(phrase in text_lower for phrase in [
                    'policies relating to political',
                    'governance system',
                    'political and governance',
                    'guarantee the best interests',
                    'maintain rule of law',
                    'good governance',
                    'mass media fair'
                ]):
                    score += 20.0  # Even more for specific governance content
        
        # 4. WORD COVERAGE SCORING (improved)
        word_matches = len(query_words.intersection(set(text_lower.split())))
        if len(query_words) > 0:
            coverage = word_matches / len(query_words)
            score += coverage * 12.0
        
        # 5. DOCUMENT TYPE RELEVANCE
        doc_lower = doc_id.lower()
        
        # Health-related queries
        if any(keyword in query_lower for keyword in ['health', 'medical', 'hospital', 'covid']):
            if any(keyword in doc_lower for keyword in ['health', 'covid', 'medical']):
                score += 15.0
            # But reduce score if asking about governance and getting health content
            elif any(keyword in query_lower for keyword in ['governance', 'political', 'constitution']):
                score *= 0.3  # Heavy penalty for wrong document type
        
        # 6. CONTENT QUALITY AND RELEVANCE
        # Prefer longer, more substantive content
        if len(text) > 500:
            score += 3.0
        elif len(text) > 200:
            score += 1.0
        
        # Look for structured content (articles, sections, etc.)
        if re.search(r'Article \d+|Section \d+|Chapter \d+|\(\d+\)', text, re.IGNORECASE):
            score += 4.0
        
        # 7. ANTI-IRRELEVANT CONTENT PENALTY
        # Penalize content that's clearly about the wrong topic
        if any(keyword in query_lower for keyword in ['governance', 'political', 'constitution']):
            if any(phrase in text_lower for phrase in ['budget allocation', 'expenditure', 'funding', 'financial']):
                if not any(phrase in text_lower for phrase in ['governance', 'political', 'constitution']):
                    score *= 0.1  # Heavy penalty for financial content when asking about governance
        
        # 8. LANGUAGE PREFERENCE
        row_lang = str(row.get('language', 'en'))
        if language_preference != "auto":
            if row_lang == language_preference:
                score += 3.0
            else:
                score *= 0.9
        
        # Only include results with meaningful relevance
        if score > 2.0:
            result = {
                'doc_id': doc_id,
                'doc_title': get_proper_title(doc_id),
                'page_num': int(row.get('page_num', 1)),
                'text': text,
                'relevance_score': round(score, 2),
                'language': row_lang,
                'char_count': len(text),
                'chunk_id': str(row.get('chunk_id', f"{doc_id}_chunk_{idx}"))
            }
            results.append(result)
    
    # Sort by relevance score and return top results
    results.sort(key=lambda x: x['relevance_score'], reverse=True)
    return results[:max_results * 2]

def generate_improved_answer(search_results: List[Dict[str, Any]], question: str) -> Dict[str, Any]:
    """Generate improved answer with better content selection."""
    
    start_time = time.time()
    
    if not search_results:
        return {
            'question': question,
            'answer': """I couldn't find specific information about this topic in the Nepal government documents. 

**Suggestions:**
- Try rephrasing your question with different keywords
- Ask about topics like: fundamental rights, health services, COVID-19 policies, emergency services, government structure
- Be more specific about what aspect you're interested in

**Available Documents Include:**
- Constitution of Nepal (fundamental rights, government structure, political system)
- Health Ministry reports and policies  
- COVID-19 response and vaccination policies
- Emergency health service protocols
- Government budget and policy documents""",
            'confidence': 0.0,
            'sources': [],
            'total_sources_found': 0,
            'processing_time_ms': round((time.time() - start_time) * 1000, 2),
            'document_coverage': {}
        }
    
    # Generate answer from top results
    answer_parts = []
    sources = []
    document_coverage = {}
    
    # Use top 3-4 results for answer generation
    top_results = search_results[:4]
    
    for i, result in enumerate(top_results):
        text = result['text']
        doc_title = result['doc_title']  # Now using proper titles!
        
        # Better text extraction for constitutional content
        if len(text) > 400:
            # For constitutional content, try to extract the most relevant section
            if 'constitution' in result['doc_id'].lower():
                # Look for numbered sections or policies
                sentences = re.split(r'(?:\.\s+|\n\s*\(\d+\)\s*)', text)
                relevant_sentences = []
                
                question_words = set(question.lower().split())
                for sentence in sentences:
                    sentence = sentence.strip()
                    if len(sentence) < 30:
                        continue
                    
                    sentence_words = set(sentence.lower().split())
                    if len(question_words.intersection(sentence_words)) >= 2:
                        relevant_sentences.append(sentence)
                        if len(relevant_sentences) >= 2:
                            break
                
                if relevant_sentences:
                    text = '. '.join(relevant_sentences) + '.'
                else:
                    # If no specific match, take the first substantial part
                    text = text[:397] + "..."
            else:
                # For non-constitutional content, use existing logic
                text = text[:397] + "..."
        
        # Format answer section with proper titles
        if i == 0 and result['relevance_score'] > 20:
            answer_parts.append(f"**According to {doc_title}:**\n{text}")
        else:
            answer_parts.append(f"**{doc_title} also states:**\n{text}")
        
        # Add to sources with proper titles
        sources.append({
            'doc_id': result['doc_id'],
            'doc_title': doc_title,  # Proper title here too!
            'page_num': result['page_num'],
            'text': text,
            'relevance_score': result['relevance_score'],
            'language': result['language'],
            'char_count': result['char_count']
        })
        
        # Update document coverage
        doc_id = result['doc_id']
        document_coverage[doc_id] = document_coverage.get(doc_id, 0) + 1
    
    # Combine answer parts
    if len(answer_parts) == 1:
        answer = answer_parts[0]
    else:
        answer = "\n\n".join(answer_parts)
    
    # Add source references with proper titles
    if sources:
        answer += "\n\n**üìö Sources:**"
        for i, source in enumerate(sources, 1):
            answer += f"\n{i}. {source['doc_title']} (Page {source['page_num']}, Relevance: {source['relevance_score']:.1f})"
    
    # Calculate confidence
    avg_relevance = sum(r['relevance_score'] for r in top_results) / len(top_results)
    confidence = min(avg_relevance / 25.0, 1.0)  # Adjusted for new scoring
    
    processing_time = round((time.time() - start_time) * 1000, 2)
    
    return {
        'question': question,
        'answer': answer,
        'confidence': round(confidence, 2),
        'sources': sources,
        'total_sources_found': len(search_results),
        'processing_time_ms': processing_time,
        'document_coverage': document_coverage
    }

@app.on_event("startup")
async def startup_event():
    """Initialize the API on startup."""
    logger.info("üöÄ Starting IMPROVED Nepal Government Q&A API...")
    if load_corpus():
        logger.info("‚úÖ API ready with improved search and proper document titles!")
    else:
        logger.error("‚ùå Failed to load document corpus!")

@app.get("/")
async def root():
    """Root endpoint with system information."""
    return {
        "title": "üá≥üáµ Nepal Government Q&A System - IMPROVED",
        "version": "2.1.0",
        "status": "operational",
        "improvements": [
            "Better search algorithm prioritizes constitutional content correctly",
            "Proper document titles instead of filenames", 
            "More accurate content matching",
            "Anti-irrelevant content penalties"
        ],
        "description": "Ask questions about Nepal's constitution, health policies, COVID-19 response, emergency services, and more",
        "total_documents": len(document_stats) if document_stats else 0,
        "total_chunks": len(corpus_data) if corpus_data is not None else 0,
        "example_questions": [
            "What are the policies relating to political and governance system of State?",
            "What are the fundamental rights in Nepal?",
            "What health services are available in Nepal?",
            "How did Nepal respond to COVID-19?"
        ]
    }

@app.post("/ask", response_model=Answer)
async def ask_question(request: QueryRequest):
    """
    Ask any question - now with IMPROVED search and proper document titles!
    """
    
    if corpus_data is None:
        raise HTTPException(status_code=503, detail="Document corpus not loaded")
    
    if not request.question.strip():
        raise HTTPException(status_code=400, detail="Question cannot be empty")
    
    try:
        # Use improved search
        search_results = improved_search(
            request.question, 
            max_results=request.max_results,
            language_preference=request.language_preference
        )
        
        # Generate improved answer
        result = generate_improved_answer(search_results, request.question)
        
        return Answer(**result)
        
    except Exception as e:
        logger.error(f"Error processing question: {e}")
        raise HTTPException(status_code=500, detail=f"Error processing question: {str(e)}")

@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {
        "status": "healthy - IMPROVED VERSION",
        "corpus_loaded": corpus_data is not None,
        "total_documents": len(document_stats) if document_stats else 0,
        "total_chunks": len(corpus_data) if corpus_data is not None else 0,
        "improvements": "Better search + proper document titles"
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("fixed_nepal_gov_api:app", host="0.0.0.0", port=8000, reload=True)


